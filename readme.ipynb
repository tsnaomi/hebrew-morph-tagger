{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with the model\n",
    "\n",
    "### Loading the data\n",
    "\n",
    "In `data/data.py`, I created a `Data()` object to extract, format, and navigate the *HaAretz* corpus. Below, I instantiate this object, which gives us access to training, development, and test datasets. Since this project is in its early stages, I will test the model here on the development set and refrain from interacting with the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from data import Data  # data is a local module\n",
    "\n",
    "data = Data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the training data, we see that `data.train_X` is a list containing the respective inputs to the word and character embedding layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First sentence vector in word-embedding input:\n",
      "[18772 12467   374 12828 16803 12500 13790  2517 15816  5001 19409  8682\n",
      " 12884 13861  2084 11977 10221     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0]\n",
      "\n",
      "First sentence vector in character-embedding input:\n",
      "[[ 1 15 46 ...  0  0  0]\n",
      " [15 40 35 ...  0  0  0]\n",
      " [17  4 31 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print('First sentence vector in word-embedding input:')\n",
    "print(data.train_X[0][0])\n",
    "print()\n",
    "print('First sentence vector in character-embedding input:')\n",
    "print(data.train_X[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To accommodate variable length words and sentences, the input vectors are zero-padded. All of the sentence vectors have been set to the length of the longest sentence in the corpus (`data.max_sent_len`). Likewise, all of the word vectors have been set to the length of the longest word in the corpus (`data.max_word_len`). Below, I have printed these values along with the shapes of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sentence length: \t\t 75\n",
      "Maximum word length: \t\t\t 16\n",
      "\n",
      "\u001b[1mTRAINING\u001b[0m\n",
      "Number of examples: \t\t\t 2822\n",
      "Shape of word embeddings input: \t (2822, 75)\n",
      "Shape of character embeddings input: \t (2822, 75, 16)\n",
      "Shape of output labels: \t\t (2822, 75, 38)\n",
      "\n",
      "\u001b[1mDEV\u001b[0m\n",
      "Number of examples: \t\t\t 353\n",
      "Shape of word embeddings input: \t (353, 75)\n",
      "Shape of character embeddings input: \t (353, 75, 16)\n",
      "Shape of output labels: \t\t (353, 75, 38)\n",
      "\n",
      "\u001b[1mTEST\u001b[0m\n",
      "Number of examples: \t\t\t 352\n",
      "Shape of word embeddings input: \t (352, 75)\n",
      "Shape of character embeddings input: \t (352, 75, 16)\n",
      "Shape of output labels: \t\t (352, 75, 38)\n"
     ]
    }
   ],
   "source": [
    "print('Maximum sentence length:', '\\t\\t', data.max_sent_len)\n",
    "print('Maximum word length:', '\\t\\t\\t', data.max_word_len)\n",
    "\n",
    "print('\\n\\033[1mTRAINING\\033[0m')\n",
    "print('Number of examples:', '\\t\\t\\t', len(data.train_X[0]))\n",
    "print('Shape of word embeddings input:', '\\t', data.train_X[0].shape)\n",
    "print('Shape of character embeddings input:', '\\t', data.train_X[1].shape)\n",
    "print('Shape of output labels:', '\\t\\t', data.train_Y.shape)\n",
    "\n",
    "print('\\n\\033[1mDEV\\033[0m')\n",
    "print('Number of examples:', '\\t\\t\\t', len(data.dev_X[0]))\n",
    "print('Shape of word embeddings input:', '\\t', data.dev_X[0].shape)\n",
    "print('Shape of character embeddings input:', '\\t', data.dev_X[1].shape)\n",
    "print('Shape of output labels:', '\\t\\t', data.dev_Y.shape)\n",
    "\n",
    "print('\\n\\033[1mTEST\\033[0m')\n",
    "print('Number of examples:', '\\t\\t\\t', len(data.test_X[0]))\n",
    "print('Shape of word embeddings input:', '\\t', data.test_X[0].shape)\n",
    "print('Shape of character embeddings input:', '\\t', data.test_X[1].shape)\n",
    "print('Shape of output labels:', '\\t\\t', data.test_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model\n",
    "\n",
    "The morphological tagger is implemented in `nn.py` as `MorphTagger`. Below, I use `MorphTagger` to load a previously trained model. However, if the tagger is passed a filename for a nonexistent file, it will train and save a new model. Whenever the model is instantiated, it will print out Keras' model summary. For now, I have hard-coded arbitrary values in `nn.py` for different parameters required by the network, such as the number of hidden units for the embedding layers (i.e., 150 for word embeddings and 200 for character embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 75, 16)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 75)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 75, 16, 200)  11200       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 75, 150)      3120750     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 75, 200)      240800      time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 75, 350)      0           embedding_1[0][0]                \n",
      "                                                                 time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 75, 200)      360800      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 75, 38)       7638        bidirectional_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 3,741,188\n",
      "Trainable params: 3,741,188\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from nn import MorphTagger\n",
    "\n",
    "MODEL_FN = './models/morph_tagger.h5'\n",
    "\n",
    "model = MorphTagger(\n",
    "    model_fn=MODEL_FN,\n",
    "    train_X=data.train_X,\n",
    "    train_Y=data.train_Y,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing with predictions\n",
    "\n",
    "With that, lets generate some predictions with `MorphTagger` and view the model's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353/353 [==============================] - 7s 20ms/step\n",
      "\n",
      "\u001b[1mPrediction accuracies given 6252 words across 353 sentences\u001b[0m:\n",
      "╒══════════════════╤═══════════╕\n",
      "│ ALL-OR-NOTHING   │   0.69002 │\n",
      "╞══════════════════╪═══════════╡\n",
      "│ POS              │   0.81942 │\n",
      "├──────────────────┼───────────┤\n",
      "│ PERSON           │   0.93138 │\n",
      "├──────────────────┼───────────┤\n",
      "│ GENDER           │   0.90739 │\n",
      "├──────────────────┼───────────┤\n",
      "│ NUMBER           │   0.88564 │\n",
      "├──────────────────┼───────────┤\n",
      "│ TENSE            │   0.94386 │\n",
      "├──────────────────┼───────────┤\n",
      "│ DEFINITENESS     │   0.86644 │\n",
      "╘══════════════════╧═══════════╛\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(data.dev_X)\n",
    "model.acc(predictions, data.dev_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is also equipped with the ability to print out a confusion matrix for the POS tags predicted by the network. This can be invoked by calling `model.pos_confusion(predictions, data.dev_Y)`, however, given the size of the matrix, I just include an image of it here.\n",
    "\n",
    "<img src=\"./images/pos-confusion.png\" alt=\"POS confusion matrix\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess the *quality* of the model's predictions, I imbued the `Data()` object  with a `decipher()` method that will return a human-readable string given an output vector; e.g., see the gold vector for a `3rd-person, singular, feminine pronoun` below. The `decipher()` method attributes a label like `singular` to a word if the model gives that label a value greater or equal to a specified threshold (e.g., `threshold=0.5`). With that said, it will always assign the part of speech with the highest value, regardless of whether that value meets the threshold, since all tokens inherently belong to a POS class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pronoun 3 feminine singular'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "label_vec = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
    "     0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])  # היא (she)\n",
    "\n",
    "data.decipher(label_vec, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fun, I randomly select a sentence here from the predictions and show the predicted and gold labels side-by-side for each word in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mהוא\u001b[0m\n",
      "pronoun 3 masculine singular indefinite (predicted)\n",
      "pronoun 3 masculine singular indefinite (gold)\n",
      "\n",
      "\u001b[1mחושב\u001b[0m\n",
      "participle 1 2 3 masculine singular indefinite (predicted)\n",
      "participle 1 2 3 masculine singular indefinite (gold)\n",
      "\n",
      "\u001b[1mשהם\u001b[0m\n",
      "pronoun 3 masculine plural indefinite (predicted)\n",
      "pronoun 3 masculine plural indefinite (gold)\n",
      "\n",
      "\u001b[1mעושים\u001b[0m\n",
      "participle 1 2 3 masculine plural indefinite (predicted)\n",
      "participle 1 2 3 masculine plural indefinite (gold)\n",
      "\n",
      "\u001b[1mסדרה\u001b[0m\n",
      "noun feminine singular indefinite (predicted)\n",
      "noun feminine singular indefinite (gold)\n",
      "\n",
      "\u001b[1mטובה\u001b[0m\n",
      "adjective feminine singular indefinite (predicted)\n",
      "adjective feminine singular indefinite (gold)\n",
      "\n",
      "\u001b[1mומצחיקה\u001b[0m\n",
      "noun feminine singular indefinite (predicted)\n",
      "adjective feminine singular indefinite (gold)\n",
      "\n",
      "\u001b[1m.\u001b[0m\n",
      "punctuation (predicted)\n",
      "punctuation (gold)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# randomly select a sentence index\n",
    "i = np.random.randint(0, high=len(data.dev_Y), size=1)[0]\n",
    "\n",
    "# compare the predictions against the gold labels for the randomly selected sentence\n",
    "for word_idx, pred, gold in zip(data.dev_X[0][i], predictions[i], data.dev_Y[i]):\n",
    "\n",
    "    # if the word is not a pad token\n",
    "    if word_idx > 1:\n",
    "        print('\\033[1m%s\\033[0m' % data.idx_word[word_idx])  # the word in Hebrew\n",
    "        print(data.decipher(pred), '(predicted)')            # the prediction\n",
    "        print(data.decipher(gold), '(gold)\\n')               # the actual/gold label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
